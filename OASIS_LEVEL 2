TASK 1
# 1. Import Libraries
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Optional: XGBoost if installed
try:
    from xgboost import XGBRegressor
except:
    XGBRegressor = None

# 2. Load Dataset
df = pd.read_csv("/mnt/data/Housing.csv")
print('Shape of data:', df.shape)
print(f"Total records: {df.shape[0]}, Total features: {df.shape[1]}")
print(df.info())
print(df.describe().round(2))

# 3. Data Cleaning
print("\nMissing values:")
print(df.isnull().sum().to_frame(name='No. of null entries'))

print(f"\nDuplicated rows: {df.duplicated().sum()}")

# 4. Visualization Functions
def target_variable_visualization(tar_col):
    plt.figure(figsize=(10, 6))

    plt.subplot(1,2,1)
    sns.histplot(df[tar_col], kde=True, color='red')
    plt.xlabel(tar_col)
    plt.ylabel('Density')
    plt.title('Price Distribution', fontweight='bold')

    plt.subplot(1,2,2)
    sns.boxplot(y=df[tar_col], palette='dark:salmon_r')
    plt.ylabel(tar_col)
    plt.title('Price Spread', fontweight='bold')

    plt.tight_layout()
    plt.show()

def categorical_variable_visualization(col):
    plt.figure(figsize=(15, 6))

    plt.subplot(1,3,1)
    sns.countplot(x=col, data=df, order=df[col].value_counts().index, palette='husl')
    plt.title(f"Count of {col}")

    plt.subplot(1,3,2)
    sns.boxplot(x=col, y='price', data=df, palette='husl')
    plt.title(f"Price Distribution by {col}")

    plt.subplot(1,3,3)
    avg_df = df.groupby(col)['price'].mean().round(2).reset_index()
    sns.barplot(x=col, y='price', data=avg_df, palette='husl')
    plt.title(f"Average Price by {col}")

    plt.tight_layout()
    plt.show()

def numerical_variable_visualization(cols):
    plt.figure(figsize=(15, 6))
    for i, col in enumerate(cols, 1):
        plt.subplot(1, len(cols), i)
        sns.regplot(x=col, y='price', data=df, scatter_kws={'color': 'red'}, line_kws={'color': 'blue'})
        plt.title(f"Price vs {col}")
    plt.tight_layout()
    plt.show()

# Example visualization
target_variable_visualization('price')

# Identify variable types
categorical_variable = df.select_dtypes(include=['object']).columns.tolist()
numerical_variable = df.select_dtypes(exclude=['object']).drop(columns='price').columns.tolist()

for col in categorical_variable:
    categorical_variable_visualization(col)

numerical_variable_visualization(numerical_variable[:3])
numerical_variable_visualization(numerical_variable[3:])

# 5. Preprocessing
X = df.drop(columns='price')
y = df[['price']]

X = pd.get_dummies(X, drop_first=True, dtype=int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

sc = StandardScaler()
X_train_sc = sc.fit_transform(X_train)
X_test_sc = sc.transform(X_test)

# 6. Model Training & Evaluation
models = {
    'Linear Regression' : LinearRegression(),
    'Lasso': Lasso(),
    'Lasso CV': LassoCV(),
    'Ridge': Ridge(),
    'Ridge CV': RidgeCV(),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

if XGBRegressor:
    models['XG Boost'] = XGBRegressor(tree_method="hist", eval_metric="mae")

def error_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred, model_name):
    return {
        'Model': model_name,
        'Train_MAE': mean_absolute_error(y_train_true, y_train_pred),
        'Train_MSE': mean_squared_error(y_train_true, y_train_pred),
        'Train_RMSE': np.sqrt(mean_squared_error(y_train_true, y_train_pred)),
        'Train_R2_Score': r2_score(y_train_true, y_train_pred),
        'Test_MAE': mean_absolute_error(y_test_true, y_test_pred),
        'Test_MSE': mean_squared_error(y_test_true, y_test_pred),
        'Test_RMSE': np.sqrt(mean_squared_error(y_test_true, y_test_pred)),
        'Test_R2_Score': r2_score(y_test_true, y_test_pred)
    }

model_evaluation = []
for name, model in models.items():
    model.fit(X_train_sc, y_train)
    y_train_pred = model.predict(X_train_sc)
    y_test_pred = model.predict(X_test_sc)
    model_evaluation.append(error_metrics(y_train, y_train_pred, y_test, y_test_pred, name))

model_evaluation_df = pd.DataFrame(model_evaluation)
print(model_evaluation_df)

TASK2

# 2. Load Dataset
df = pd.read_csv("Housing.csv")
print('Shape of data:', df.shape)
print(f"Total records: {df.shape[0]}, Total features: {df.shape[1]}")
print(df.info())
print(df.describe().round(2))
# 3. Data Cleaning
print("\nMissing values:")
print(df.isnull().sum().to_frame(name='No. of null entries'))

print(f"\nDuplicated rows: {df.duplicated().sum()}")

# 4. Visualization Functions
def target_variable_visualization(tar_col):
    plt.figure(figsize=(10, 6))

    plt.subplot(1,2,1)
    sns.histplot(df[tar_col], kde=True, color='red')
    plt.xlabel(tar_col)
    plt.ylabel('Density')
    plt.title('Price Distribution', fontweight='bold')

    plt.subplot(1,2,2)
    sns.boxplot(y=df[tar_col], palette='dark:salmon_r')
    plt.ylabel(tar_col)
    plt.title('Price Spread', fontweight='bold')

    plt.tight_layout()
    plt.show()

def categorical_variable_visualization(col):
    plt.figure(figsize=(15, 6))

    plt.subplot(1,3,1)
    sns.countplot(x=col, data=df, order=df[col].value_counts().index, palette='husl')
    plt.title(f"Count of {col}")

    plt.subplot(1,3,2)
    sns.boxplot(x=col, y='price', data=df, palette='husl')
    plt.title(f"Price Distribution by {col}")

    plt.subplot(1,3,3)
    avg_df = df.groupby(col)['price'].mean().round(2).reset_index()
    sns.barplot(x=col, y='price', data=avg_df, palette='husl')
    plt.title(f"Average Price by {col}")

    plt.tight_layout()
    plt.show()

def numerical_variable_visualization(cols):
    plt.figure(figsize=(15, 6))
    for i, col in enumerate(cols, 1):
        plt.subplot(1, len(cols), i)
        sns.regplot(x=col, y='price', data=df, scatter_kws={'color': 'red'}, line_kws={'color': 'blue'})
        plt.title(f"Price vs {col}")
    plt.tight_layout()
    plt.show()

# Example visualization
target_variable_visualization('price')

# Identify variable types
categorical_variable = df.select_dtypes(include=['object']).columns.tolist()
numerical_variable = df.select_dtypes(exclude=['object']).drop(columns='price').columns.tolist()

for col in categorical_variable:
    categorical_variable_visualization(col)

numerical_variable_visualization(numerical_variable[:3])
numerical_variable_visualization(numerical_variable[3:])

# 6. Model Training & Evaluation
models = {
    'Linear Regression' : LinearRegression(),
    'Lasso': Lasso(),
    'Lasso CV': LassoCV(),
    'Ridge': Ridge(),
    'Ridge CV': RidgeCV(),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

if XGBRegressor:
    models['XG Boost'] = XGBRegressor(tree_method="hist", eval_metric="mae")

def error_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred, model_name):
    return {
        'Model': model_name,
        'Train_MAE': mean_absolute_error(y_train_true, y_train_pred),
        'Train_MSE': mean_squared_error(y_train_true, y_train_pred),
        'Train_RMSE': np.sqrt(mean_squared_error(y_train_true, y_train_pred)),
        'Train_R2_Score': r2_score(y_train_true, y_train_pred),
        'Test_MAE': mean_absolute_error(y_test_true, y_test_pred),
        'Test_MSE': mean_squared_error(y_test_true, y_test_pred),
        'Test_RMSE': np.sqrt(mean_squared_error(y_test_true, y_test_pred)),
        'Test_R2_Score': r2_score(y_test_true, y_test_pred)
    }

model_evaluation = []
for name, model in models.items():
    model.fit(X_train_sc, y_train)
    y_train_pred = model.predict(X_train_sc)
    y_test_pred = model.predict(X_test_sc)
    model_evaluation.append(error_metrics(y_train, y_train_pred, y_test, y_test_pred, name))

model_evaluation_df = pd.DataFrame(model_evaluation)
print(model_evaluation_df)

TASK2 
# 1. Import Libraries
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Optional XGBoost
try:
    from xgboost import XGBRegressor
except:
    XGBRegressor = None
# 2. Load Dataset
df = pd.read_csv("WineQT.csv")
print('Shape of data:', df.shape)
print(df.info())
print(df.describe().round(2))
# 3. Data Cleaning
print("\nMissing values:\n", df.isnull().sum())
print(f"\nDuplicated rows: {df.duplicated().sum()}")
# 4. Visualization Functions
def target_variable_visualization(tar_col):
    plt.figure(figsize=(10, 6))
    plt.subplot(1,2,1)
    sns.histplot(df[tar_col], kde=True, color='red')
    plt.title(f'{tar_col} Distribution')

    plt.subplot(1,2,2)
    sns.boxplot(y=df[tar_col], palette='Set2')
    plt.title(f'{tar_col} Spread')
    plt.tight_layout()
    plt.show()

def numerical_variable_visualization(cols, target='quality'):
    plt.figure(figsize=(15, 6))
    for i, col in enumerate(cols, 1):
        plt.subplot(1, len(cols), i)
        sns.regplot(x=col, y=target, data=df, scatter_kws={'color': 'red'}, line_kws={'color': 'blue'})
        plt.title(f'{target} vs {col}')
    plt.tight_layout()
    plt.show()

# Show target variable
target_variable_visualization('quality')

# Get column types
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
numerical_cols = df.select_dtypes(exclude=['object']).drop(columns=['quality']).columns.tolist()

# Visualize numerical variables
for chunk_start in range(0, len(numerical_cols), 3):
    numerical_variable_visualization(numerical_cols[chunk_start:chunk_start+3])

# 5. Preprocessing
X = df.drop(columns='quality')
y = df[['quality']]

X = pd.get_dummies(X, drop_first=True, dtype=int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc = scaler.transform(X_test)
# 6. Models
models = {
    'Linear Regression': LinearRegression(),
    'Lasso': Lasso(),
    'Lasso CV': LassoCV(),
    'Ridge': Ridge(),
    'Ridge CV': RidgeCV(),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

if XGBRegressor:
    models['XGBoost'] = XGBRegressor(tree_method="hist", eval_metric="mae")

# Evaluation function
def error_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred, model_name):
    return {
        'Model': model_name,
        'Train_MAE': mean_absolute_error(y_train_true, y_train_pred),
        'Train_MSE': mean_squared_error(y_train_true, y_train_pred),
        'Train_RMSE': np.sqrt(mean_squared_error(y_train_true, y_train_pred)),
        'Train_R2': r2_score(y_train_true, y_train_pred),
        'Test_MAE': mean_absolute_error(y_test_true, y_test_pred),
        'Test_MSE': mean_squared_error(y_test_true, y_test_pred),
        'Test_RMSE': np.sqrt(mean_squared_error(y_test_true, y_test_pred)),
        'Test_R2': r2_score(y_test_true, y_test_pred)
    }

# 7. Model Training & Evaluation
model_results = []
for name, model in models.items():
    model.fit(X_train_sc, y_train)
    y_train_pred = model.predict(X_train_sc)
    y_test_pred = model.predict(X_test_sc)
    model_results.append(error_metrics(y_train, y_train_pred, y_test, y_test_pred, name))

results_df = pd.DataFrame(model_results)
print(results_df)

TASK 4
# 1. Import Libraries
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

# Optional XGBoost
try:
    from xgboost import XGBRegressor
except:
    XGBRegressor = None
# 2. Load Datasets
apps = pd.read_csv("apps.csv")
reviews = pd.read_csv("user_reviews.csv")

print("Apps shape:", apps.shape)
print("Reviews shape:", reviews.shape)
# 3. Merge on App name
df = pd.merge(apps, reviews, on="App", how="left")
# 4. Data Cleaning
df.drop_duplicates(inplace=True)

# Remove '+' and ',' in Installs column
df['Installs'] = df['Installs'].str.replace('+', '', regex=False).str.replace(',', '', regex=False).astype(float)

# Remove '$' from Price column
df['Price'] = df['Price'].str.replace('$', '', regex=False).astype(float)

# Convert Reviews to numeric
df['Reviews'] = pd.to_numeric(df['Reviews'], errors='coerce')

# Handle missing values
df.fillna(df.median(numeric_only=True), inplace=True)

print("\nMissing values after cleaning:", df.isnull().sum().sum())
# 5. Visualization
plt.figure(figsize=(8,5))
sns.histplot(df['Rating'], kde=True, color='orange')
plt.title("Distribution of Ratings")
plt.show()

plt.figure(figsize=(10,6))
sns.boxplot(x='Category', y='Rating', data=df)
plt.xticks(rotation=90)
plt.title("Rating by App Category")
plt.show()

# Correlation Heatmap
plt.figure(figsize=(10,8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()
# 6. Preprocessing
X = df.drop(columns=['Rating', 'App'])
y = df[['Rating']]

X = pd.get_dummies(X, drop_first=True, dtype=int)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train_sc = scaler.fit_transform(X_train)
X_test_sc = scaler.transform(X_test)
# 7. Models
models = {
    'Linear Regression': LinearRegression(),
    'Lasso': Lasso(),
    'Lasso CV': LassoCV(),
    'Ridge': Ridge(),
    'Ridge CV': RidgeCV(),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

if XGBRegressor:
    models['XGBoost'] = XGBRegressor(tree_method="hist", eval_metric="mae")

# Evaluation Function
def error_metrics(y_train_true, y_train_pred, y_test_true, y_test_pred, model_name):
    return {
        'Model': model_name,
        'Train_MAE': mean_absolute_error(y_train_true, y_train_pred),
        'Train_RMSE': np.sqrt(mean_squared_error(y_train_true, y_train_pred)),
        'Train_R2': r2_score(y_train_true, y_train_pred),
        'Test_MAE': mean_absolute_error(y_test_true, y_test_pred),
        'Test_RMSE': np.sqrt(mean_squared_error(y_test_true, y_test_pred)),
        'Test_R2': r2_score(y_test_true, y_test_pred)
    }
# 8. Model Training & Evaluation
results = []
for name, model in models.items():
    model.fit(X_train_sc, y_train)
    y_train_pred = model.predict(X_train_sc)
    y_test_pred = model.predict(X_test_sc)
    results.append(error_metrics(y_train, y_train_pred, y_test, y_test_pred, name))

results_df = pd.DataFrame(results)
print(results_df)

TASK (3 & 5)

import pandas as pd
import numpy as np

#importing the data set
df=pd.read_csv("C:/Users/sethi/Desktop/Fall 2016/Practice/Kaggle/Credit Card Fraud/Data set.csv")

#creating target series
target=df['Class']
target

#dropping the target variable from the data set
df.drop('Class',axis=1,inplace=True)
df.shape

#converting them to numpy arrays
X=np.array(df)
y=np.array(target)
X.shape
y.shape

#distribution of the target variable
len(y[y==1])
len(y[y==0])

#splitting the data set into train and test (75:25)
from sklearn.cross_validation import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=1)
print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)

#applyting SMOTE to oversample the minority class
from imblearn.over_sampling import SMOTE
sm=SMOTE(random_state=2)
X_sm,y_sm=sm.fit_sample(X_train,y_train)
print(X_sm.shape,y_sm.shape)
print(len(y_sm[y_sm==1]),len(y_sm[y_sm==0]))

from sklearn.linear_model import LogisticRegression
import matplotlib.pyplot as plt
from sklearn import metrics

#Logistic Regression
logreg=LogisticRegression()
logreg.fit(X_sm,y_sm)
y_logreg=logreg.predict(X_test)
y_logreg_prob=logreg.predict_proba(X_test)[:,1]

#Performance metrics evaluation
print("Confusion Matrix:\n",metrics.confusion_matrix(y_test,y_logreg))
print("Accuracy:\n",metrics.accuracy_score(y_test,y_logreg))
print("Precision:\n",metrics.precision_score(y_test,y_logreg))
print("Recall:\n",metrics.recall_score(y_test,y_logreg))
print("AUC:\n",metrics.roc_auc_score(y_test,y_logreg_prob))
auc=metrics.roc_auc_score(y_test,y_logreg_prob)

#plotting the ROC curve
fpr,tpr,thresholds=metrics.roc_curve(y_test,y_logreg_prob)
plt.plot(fpr,tpr,'b', label='AUC = %0.2f'% auc)
plt.plot([0,1],[0,1],'r-.')
plt.xlim([-0.2,1.2])
plt.ylim([-0.2,1.2])
plt.title('Receiver Operating Characteristic\nLogistic Regression')
plt.legend(loc='lower right')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

#K Nearest Neighbors
from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier(n_neighbors=5)
knn.fit(X_sm,y_sm)
y_knn=knn.predict(X_test)
y_knn_prob=knn.predict_proba(X_test)[:,1]

#metrics evaluation
print(metrics.confusion_matrix(y_test,y_knn))
print(metrics.accuracy_score(y_test,y_knn))
print(metrics.precision_score(y_test,y_knn))
print(metrics.recall_score(y_test,y_knn))
print(metrics.roc_auc_score(y_test,y_knn_prob))

#plotting the ROC curve
fpr,tpr,thresholds=metrics.roc_curve(y_test,y_knn_prob)
plt.plot(fpr,tpr)
plt.xlim([0.0,1.0])
plt.ylim([0.0,1.0])
plt.show()

#Random Forest
from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier(random_state=3)
rf.fit(X_sm,y_sm)
y_rf=rf.predict(X_test)
y_rf_prob=rf.predict_proba(X_test)[:,1]

#Performance metrics evaluation
print("Confusion Matrix:\n",metrics.confusion_matrix(y_test,y_rf))
print("Accuracy:\n",metrics.accuracy_score(y_test,y_rf))
print("Precision:\n",metrics.precision_score(y_test,y_rf))
print("Recall:\n",metrics.recall_score(y_test,y_rf))
print("AUC:\n",metrics.roc_auc_score(y_test,y_rf_prob))
auc=metrics.roc_auc_score(y_test,y_rf_prob)

#plotting the ROC curve
fpr,tpr,thresholds=metrics.roc_curve(y_test,y_rf_prob)
plt.plot(fpr,tpr,'b', label='AUC = %0.2f'% auc)
plt.plot([0,1],[0,1],'r-.')
plt.xlim([-0.2,1.2])
plt.ylim([-0.2,1.2])
plt.title('Receiver Operating Characteristic\nRandom Forest')
plt.legend(loc='lower right')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

#Random Forest
from sklearn.ensemble import RandomForestClassifier

rf=RandomForestClassifier(criterion='entropy',random_state=3)
rf.fit(X_sm,y_sm)
y_rf=rf.predict(X_test)
y_rf_prob=rf.predict_proba(X_test)[:,1]

#Performance metrics evaluation
print("Confusion Matrix:\n",metrics.confusion_matrix(y_test,y_rf))
print("Accuracy:\n",metrics.accuracy_score(y_test,y_rf))
print("Precision:\n",metrics.precision_score(y_test,y_rf))
print("Recall:\n",metrics.recall_score(y_test,y_rf))
print("AUC:\n",metrics.roc_auc_score(y_test,y_rf_prob))
auc=metrics.roc_auc_score(y_test,y_rf_prob)

#plotting the ROC curve
fpr,tpr,thresholds=metrics.roc_curve(y_test,y_rf_prob)
plt.plot(fpr,tpr,'b', label='AUC = %0.2f'% auc)
plt.plot([0,1],[0,1],'r-.')
plt.xlim([-0.2,1.2])
plt.ylim([-0.2,1.2])
plt.title('Receiver Operating Characteristic\nRandom Forest')
plt.legend(loc='lower right')
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()
